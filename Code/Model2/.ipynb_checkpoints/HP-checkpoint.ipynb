{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "948828df-b0b9-480c-924f-765b13dd48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Packages\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, Huber\n",
    "from tensorflow.keras.backend import sqrt, mean, square\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f9b836-43d0-422a-9869-18a41bd72f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tile Read and Prepare Data\n",
    "\n",
    "def read_prepare_data(symbol):\n",
    "    #read\n",
    "    data = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/dataset4.csv')\n",
    "    train = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/train.csv')\n",
    "    test = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/test.csv')\n",
    "    \n",
    "    #we're going to use only one symbol\n",
    "    data = data[data['Symbol'] == symbol].copy()\n",
    "    train = train[train['Symbol'] == symbol].copy()\n",
    "    test = test[test['Symbol'] == symbol].copy()\n",
    "    \n",
    "    #we're going to use the price variable\n",
    "    data = data[['Date', 'Close']].copy()\n",
    "    train = train[['Date', 'Close']].copy()\n",
    "    test = test[['Date', 'Close']].copy()\n",
    "    \n",
    "    #set date as index\n",
    "    data.set_index('Date', inplace=True)\n",
    "    train.set_index('Date', inplace=True)\n",
    "    test.set_index('Date', inplace=True)\n",
    "\n",
    "    #normalize\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)\n",
    "    test = pd.DataFrame(scaler.transform(test), columns=test.columns, index=test.index)\n",
    "    data = pd.DataFrame(scaler.transform(data), columns=data.columns, index=data.index) \n",
    "\n",
    "    return scaler, data, train, test\n",
    "\n",
    "scaler, data, train, test = read_prepare_data('AAPL')\n",
    "\n",
    "#verify\n",
    "#print(data.head())\n",
    "#print(data.index)   \n",
    "#print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4e848e-9d58-4459-b1cf-12d193392b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create Dataset\n",
    "\n",
    "def create_dataset(dataframe, look_back):\n",
    "    dataset = dataframe.values\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e245fb-7560-414e-a5fe-98767db5472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Reshape\n",
    "\n",
    "def reshape(train, test, look_back):\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99e6277-bf9f-4ec9-be17-f4871115cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Forecast\n",
    "\n",
    "def forecast_values(testY, look_back, horizon, model):\n",
    "    testY_copy = testY.copy()\n",
    "    for val in range(0, horizon+1):\n",
    "        a = testY_copy[-(1+look_back):-1]\n",
    "        a = np.reshape(a, (1, look_back, 1)) \n",
    "        a_predict = model.predict(a, verbose=0)[0]\n",
    "        a_predict = np.reshape(a_predict, (1, 1))\n",
    "        testY_copy = np.concatenate((testY_copy, a_predict), axis=0)\n",
    "    \n",
    "    forecast = testY_copy[len(testY):]\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e7e59e-4ced-45f6-99e2-ec605591ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Auxiliary Function\n",
    "\n",
    "def predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model):\n",
    "    #make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    \n",
    "    #forecast\n",
    "    forecast = forecast_values(testY, look_back, horizon, model)\n",
    "\n",
    "    #invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform(trainY)\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform(testY)\n",
    "    forecast = scaler.inverse_transform(forecast)\n",
    "\n",
    "    #calculate root mean squared error\n",
    "    trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = np.sqrt(mean_squared_error(testY, testPredict))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "    #plot predictions\n",
    "    if plot_predictions==True: \n",
    "        #shift train predictions for plotting\n",
    "        trainPredictPlot = np.empty_like(data)\n",
    "        trainPredictPlot[:, :] = np.nan\n",
    "        trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "        \n",
    "        #shift test predictions for plotting\n",
    "        testPredictPlot = np.empty_like(data)\n",
    "        testPredictPlot[:, :] = np.nan\n",
    "        testPredictPlot[len(trainPredict)+(look_back*2)+1:len(data)-1, :] = testPredict\n",
    "        \n",
    "        #shift forecast for plotting\n",
    "        forecastPlot = np.empty_like(pd.concat([data, pd.DataFrame(forecast)]))\n",
    "        forecastPlot[:, :] = np.nan\n",
    "        forecastPlot[len(data):len(forecastPlot),:] = forecast\n",
    "        \n",
    "        #plot baseline, predictions and forecast\n",
    "        plt.figure(figsize=(15,7))\n",
    "        plt.plot(scaler.inverse_transform(data), label='real')\n",
    "        plt.plot(trainPredictPlot, label='train set prediction')\n",
    "        plt.plot(testPredictPlot, label='test set prediction')\n",
    "        plt.plot(forecastPlot, label='forecast')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178316e8-3d80-40d6-abdb-43d4b8f774ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Train and Predict\n",
    "\n",
    "def rmse_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, \n",
    "          batch_size=1, learning_rate=0.001, optimizer='adam', activation='relu', loss='mse'):\n",
    "    \n",
    "    trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "\n",
    "    input_layer = Input(shape=(trainX.shape[1], trainX.shape[2]))\n",
    "\n",
    "    if activation == 'leaky_relu':\n",
    "        x = GRU(8)(input_layer)\n",
    "        x = LeakyReLU(alpha=0.01)(x)\n",
    "    else:\n",
    "        x = GRU(8, activation=activation)(input_layer)\n",
    "\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    model_instance = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    optimizer = optimizer.lower()\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "        opt = Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adadelta':\n",
    "        opt = Adadelta(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer}\")\n",
    "\n",
    "    loss = loss.lower()\n",
    "    if loss == 'mse':\n",
    "        loss_fn = MeanSquaredError()\n",
    "    elif loss == 'rmse':\n",
    "        loss_fn = rmse_loss\n",
    "    elif loss == 'mae':\n",
    "        loss_fn = MeanAbsoluteError()\n",
    "    elif loss == 'mape':\n",
    "        loss_fn = MeanAbsolutePercentageError()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported loss function: {loss}\")\n",
    "\n",
    "    model_instance.compile(loss=loss_fn, optimizer=opt)\n",
    "\n",
    "    model_instance.fit(trainX, trainY, epochs=nepochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    testScore = predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, \n",
    "                                      nepochs, look_back, horizon, plot_predictions, model_instance)\n",
    "\n",
    "    return testScore\n",
    "\n",
    "#model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, batch_size=1, learning_rate=0.001, optimizer='adam', activation='relu', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214500c0-f956-4780-9d34-88cedfac49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optimize Batch Sizes\n",
    "\n",
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "n_runs = 5\n",
    "results = {}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    rmse_list = []\n",
    "    for _ in range(n_runs):\n",
    "        rmse = model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, batch_size=batch_size, learning_rate=0.001, optimizer='adam', activation='relu', loss='mean_squared_error')\n",
    "        rmse_list.append(rmse)\n",
    "    mean_rmse = sum(rmse_list) / n_runs\n",
    "    results[f\"Batch Size ={batch_size}\"] = {'mean': mean_rmse}\n",
    "\n",
    "print(\"Final results for Batch Sizes:\")\n",
    "for config_name, config_results in results.items():\n",
    "    print(f\"{config_name}: Mean RMSE = {config_results['mean']:.2f}\")\n",
    "best_config = min(results.items(), key=lambda x: x[1]['mean'])\n",
    "print(f\"\\nBest Configuration: {best_config[0]}\")\n",
    "print(f\"Best Mean RMSE: {best_config[1]['mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af7347-73b3-433d-bbb3-906ac117c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optimize Learning Rates\n",
    "\n",
    "learning_rates = [0.00001, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "n_runs = 5\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    rmse_list = []\n",
    "    for _ in range(n_runs):\n",
    "        rmse = model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, batch_size=1, learning_rate=lr, optimizer='adam', activation='relu', loss='mean_squared_error')\n",
    "        rmse_list.append(rmse)\n",
    "    mean_rmse = sum(rmse_list) / n_runs\n",
    "    results[f\"Learning Rate ={lr}\"] = {'mean': mean_rmse}\n",
    "\n",
    "print(\"Final results for Learning Rates:\")\n",
    "for config_name, config_results in results.items():\n",
    "    print(f\"{config_name}: Mean RMSE = {config_results['mean']:.2f}\")\n",
    "best_config = min(results.items(), key=lambda x: x[1]['mean'])\n",
    "print(f\"\\nBest Configuration: {best_config[0]}\")\n",
    "print(f\"Best Mean RMSE: {best_config[1]['mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df70b6-b048-48a9-8ec5-6e9d20963947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optimize Optimizer\n",
    "\n",
    "optimizers = ['sgd', 'adagrad', 'adadelta', 'rmsprop', 'adam']\n",
    "n_runs = 5\n",
    "results = {}\n",
    "\n",
    "for opt_name in optimizers:\n",
    "    rmse_list = []\n",
    "    for _ in range(n_runs):\n",
    "        rmse = model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, batch_size=1, learning_rate=0.001, optimizer=opt_name, activation='relu', loss='mean_squared_error')\n",
    "        rmse_list.append(rmse)\n",
    "    mean_rmse = sum(rmse_list) / n_runs\n",
    "    results[f\"Optimizer = {opt_name}\"] = {'mean': mean_rmse}\n",
    "\n",
    "print(\"Final results for Optimizers:\")\n",
    "for config_name, config_results in results.items():\n",
    "    print(f\"{config_name}: Mean RMSE = {config_results['mean']:.5f}\")\n",
    "best_config = min(results.items(), key=lambda x: x[1]['mean'])\n",
    "print(f\"\\nBest Configuration: {best_config[0]}\")\n",
    "print(f\"Best Mean RMSE: {best_config[1]['mean']:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ce3a6-e7d2-4de1-bedc-45408182ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optimize Activation Functions\n",
    "\n",
    "activations = ['tanh', 'softmax', 'sigmoid', 'hardsigmoid', 'relu', 'leaky_relu']\n",
    "n_runs = 5\n",
    "results = {}\n",
    "\n",
    "for act in activations:\n",
    "    rmse_list = []\n",
    "    for _ in range(n_runs):\n",
    "        rmse = model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, batch_size=1, learning_rate=0.001, optimizer='adam', activation=act, loss='mean_squared_error')\n",
    "        rmse_list.append(rmse)\n",
    "    mean_rmse = sum(rmse_list) / n_runs\n",
    "    results[f\"Activation = {act}\"] = {'mean': mean_rmse}\n",
    "\n",
    "print(\"Final results for Activation Functions:\")\n",
    "for config_name, config_results in results.items():\n",
    "    print(f\"{config_name}: Mean RMSE = {config_results['mean']:.2f}\")\n",
    "best_config = min(results.items(), key=lambda x: x[1]['mean'])\n",
    "print(f\"\\nBest Configuration: {best_config[0]}\")\n",
    "print(f\"Best Mean RMSE: {best_config[1]['mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b713ff3-1f0c-45e6-9333-a71f0e017527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optimize Loss Functions\n",
    "\n",
    "loss_functions = ['mse', 'rmse', 'mae', 'mape']\n",
    "n_runs = 5\n",
    "results = {}\n",
    "\n",
    "for loss_name in loss_functions:\n",
    "    rmse_list = []\n",
    "    for _ in range(n_runs):\n",
    "        rmse = model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, batch_size=1, learning_rate=0.001, optimizer='adam', activation='relu', loss=loss_name)\n",
    "        rmse_list.append(rmse)\n",
    "    mean_rmse = sum(rmse_list) / n_runs\n",
    "    results[f\"Loss = {loss_name.upper()}\"] = {'mean': mean_rmse}\n",
    "\n",
    "print(\"Final results for Loss Functions:\")\n",
    "for config_name, config_results in results.items():\n",
    "    print(f\"{config_name}: Mean RMSE = {config_results['mean']:.2f}\")\n",
    "best_config = min(results.items(), key=lambda x: x[1]['mean'])\n",
    "print(f\"\\nBest Configuration: {best_config[0]}\")\n",
    "print(f\"Best Mean RMSE: {best_config[1]['mean']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
