{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "948828df-b0b9-480c-924f-765b13dd48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Packages\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, Huber\n",
    "from tensorflow.keras.backend import sqrt, mean, square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f9b836-43d0-422a-9869-18a41bd72f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tile Read and Prepare Data\n",
    "\n",
    "def read_prepare_data(symbol):\n",
    "    #read\n",
    "    data = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/dataset4.csv')\n",
    "    train = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/train.csv')\n",
    "    test = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/test.csv')\n",
    "    \n",
    "    #we're going to use only one symbol\n",
    "    data = data[data['Symbol'] == symbol].copy()\n",
    "    train = train[train['Symbol'] == symbol].copy()\n",
    "    test = test[test['Symbol'] == symbol].copy()\n",
    "    \n",
    "    #we're going to use the price variable\n",
    "    data = data[['Date', 'Close']].copy()\n",
    "    train = train[['Date', 'Close']].copy()\n",
    "    test = test[['Date', 'Close']].copy()\n",
    "    \n",
    "    #set date as index\n",
    "    data.set_index('Date', inplace=True)\n",
    "    train.set_index('Date', inplace=True)\n",
    "    test.set_index('Date', inplace=True)\n",
    "\n",
    "    #normalize\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)\n",
    "    test = pd.DataFrame(scaler.transform(test), columns=test.columns, index=test.index)\n",
    "    data = pd.DataFrame(scaler.transform(data), columns=data.columns, index=data.index) \n",
    "\n",
    "    return scaler, data, train, test\n",
    "\n",
    "scaler, data, train, test = read_prepare_data('AAPL')\n",
    "\n",
    "#verify\n",
    "#print(data.head())\n",
    "#print(data.index)   \n",
    "#print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4e848e-9d58-4459-b1cf-12d193392b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create Dataset\n",
    "\n",
    "def create_dataset(dataframe, look_back):\n",
    "    dataset = dataframe.values\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e245fb-7560-414e-a5fe-98767db5472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Reshape\n",
    "\n",
    "def reshape(train, test, look_back):\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99e6277-bf9f-4ec9-be17-f4871115cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Forecast\n",
    "\n",
    "def forecast_values(testY, look_back, horizon, model):\n",
    "    testY_copy = testY.copy()\n",
    "    for val in range(0, horizon+1):\n",
    "        a = testY_copy[-(1+look_back):-1]\n",
    "        a = np.reshape(a, (1, look_back, 1)) \n",
    "        a_predict = model.predict(a, verbose=0)[0]\n",
    "        a_predict = np.reshape(a_predict, (1, 1))\n",
    "        testY_copy = np.concatenate((testY_copy, a_predict), axis=0)\n",
    "    \n",
    "    forecast = testY_copy[len(testY):]\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e7e59e-4ced-45f6-99e2-ec605591ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Auxiliary Function\n",
    "\n",
    "def predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model):\n",
    "    #make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    \n",
    "    #forecast\n",
    "    forecast = forecast_values(testY, look_back, horizon, model)\n",
    "\n",
    "    #invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform(trainY)\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform(testY)\n",
    "    forecast = scaler.inverse_transform(forecast)\n",
    "\n",
    "    #calculate root mean squared error\n",
    "    trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = np.sqrt(mean_squared_error(testY, testPredict))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "    #plot predictions\n",
    "    if plot_predictions==True: \n",
    "        #shift train predictions for plotting\n",
    "        trainPredictPlot = np.empty_like(data)\n",
    "        trainPredictPlot[:, :] = np.nan\n",
    "        trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "        \n",
    "        #shift test predictions for plotting\n",
    "        testPredictPlot = np.empty_like(data)\n",
    "        testPredictPlot[:, :] = np.nan\n",
    "        testPredictPlot[len(trainPredict)+(look_back*2)+1:len(data)-1, :] = testPredict\n",
    "        \n",
    "        #shift forecast for plotting\n",
    "        forecastPlot = np.empty_like(pd.concat([data, pd.DataFrame(forecast)]))\n",
    "        forecastPlot[:, :] = np.nan\n",
    "        forecastPlot[len(data):len(forecastPlot),:] = forecast\n",
    "        \n",
    "        #plot baseline, predictions and forecast\n",
    "        plt.figure(figsize=(15,7))\n",
    "        plt.plot(scaler.inverse_transform(data), label='real')\n",
    "        plt.plot(trainPredictPlot, label='train set prediction')\n",
    "        plt.plot(testPredictPlot, label='test set prediction')\n",
    "        plt.plot(forecastPlot, label='forecast')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178316e8-3d80-40d6-abdb-43d4b8f774ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Train and Predict\n",
    "\n",
    "def rmse_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, \n",
    "          batch_size=1, learning_rate=0.001, optimizer='adam', activation='relu', loss='mse'):\n",
    "    \n",
    "    trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "\n",
    "    input_layer = Input(shape=(trainX.shape[1], trainX.shape[2]))\n",
    "\n",
    "    if activation == 'leaky_relu':\n",
    "        x = GRU(8)(input_layer)\n",
    "        x = LeakyReLU(alpha=0.01)(x)\n",
    "    else:\n",
    "        x = GRU(8, activation=activation)(input_layer)\n",
    "\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    model_instance = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    optimizer = optimizer.lower()\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "        opt = Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adadelta':\n",
    "        opt = Adadelta(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer}\")\n",
    "\n",
    "    loss = loss.lower()\n",
    "    if loss == 'mse':\n",
    "        loss_fn = MeanSquaredError()\n",
    "    elif loss == 'rmse':\n",
    "        loss_fn = rmse_loss\n",
    "    elif loss == 'mae':\n",
    "        loss_fn = MeanAbsoluteError()\n",
    "    elif loss == 'mape':\n",
    "        loss_fn = MeanAbsolutePercentageError()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported loss function: {loss}\")\n",
    "\n",
    "    model_instance.compile(loss=loss_fn, optimizer=opt)\n",
    "\n",
    "    model_instance.fit(trainX, trainY, epochs=nepochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    testScore = predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, \n",
    "                                      nepochs, look_back, horizon, plot_predictions, model_instance)\n",
    "\n",
    "    return testScore\n",
    "\n",
    "#model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False, batch_size=1, learning_rate=0.001, optimizer='adam', activation='relu', loss='mean_squared_error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
