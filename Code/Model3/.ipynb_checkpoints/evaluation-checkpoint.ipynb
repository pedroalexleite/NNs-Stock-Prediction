{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948828df-b0b9-480c-924f-765b13dd48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Packages\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error, r2_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, LeakyReLU, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.backend import sqrt, mean, square\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9b836-43d0-422a-9869-18a41bd72f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tile Read and Prepare Data\n",
    "\n",
    "def read_prepare_data(symbol):\n",
    "    #read\n",
    "    data = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/dataset4.csv')\n",
    "    train = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/train.csv')\n",
    "    test = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/test.csv')\n",
    "    \n",
    "    #we're going to use only one symbol\n",
    "    data = data[data['Symbol'] == symbol].copy()\n",
    "    train = train[train['Symbol'] == symbol].copy()\n",
    "    test = test[test['Symbol'] == symbol].copy()\n",
    "    \n",
    "    #we're going to use the price variable\n",
    "    data = data[['Date', 'Close']].copy()\n",
    "    train = train[['Date', 'Close']].copy()\n",
    "    test = test[['Date', 'Close']].copy()\n",
    "    \n",
    "    #set date as index\n",
    "    data.set_index('Date', inplace=True)\n",
    "    train.set_index('Date', inplace=True)\n",
    "    test.set_index('Date', inplace=True)\n",
    "\n",
    "    #normalize\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)\n",
    "    test = pd.DataFrame(scaler.transform(test), columns=test.columns, index=test.index)\n",
    "    data = pd.DataFrame(scaler.transform(data), columns=data.columns, index=data.index) \n",
    "\n",
    "    return scaler, data, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e848e-9d58-4459-b1cf-12d193392b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create Dataset\n",
    "\n",
    "def create_dataset(dataframe, look_back):\n",
    "    dataset = dataframe.values\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e245fb-7560-414e-a5fe-98767db5472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Reshape\n",
    "\n",
    "def reshape(train, test, look_back):\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e6277-bf9f-4ec9-be17-f4871115cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Forecast\n",
    "\n",
    "def forecast_values(testY, look_back, horizon, model):\n",
    "    testY_copy = testY.copy()\n",
    "    for val in range(0, horizon+1):\n",
    "        a = testY_copy[-(1+look_back):-1]\n",
    "        a = np.reshape(a, (1, look_back, 1)) \n",
    "        a_predict = model.predict(a, verbose=0)[0]\n",
    "        a_predict = np.reshape(a_predict, (1, 1))\n",
    "        testY_copy = np.concatenate((testY_copy, a_predict), axis=0)\n",
    "    \n",
    "    forecast = testY_copy[len(testY):]\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082fd3c-a9a2-499c-995b-27a252cd3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Calculate All Metrics\n",
    "\n",
    "def calculate_all_metrics(actual, predicted):\n",
    "    #regression\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mape = np.mean(np.abs((actual - predicted) / np.where(actual != 0, actual, 1))) * 100\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    \n",
    "    #classification (auxiliary)\n",
    "    actual_direction = np.sign(np.diff(actual.flatten()))\n",
    "    predicted_direction = np.sign(np.diff(predicted.flatten()))\n",
    "    actual_binary = (actual_direction >= 0).astype(int)\n",
    "    predicted_binary = (predicted_direction >= 0).astype(int)\n",
    "    \n",
    "    #classification\n",
    "    accuracy = accuracy_score(actual_binary, predicted_binary) * 100\n",
    "    precision = precision_score(actual_binary, predicted_binary, zero_division=0) * 100\n",
    "    recall = recall_score(actual_binary, predicted_binary, zero_division=0) * 100\n",
    "    f1 = f1_score(actual_binary, predicted_binary, zero_division=0) * 100\n",
    "    \n",
    "    return rmse, mse, mae, mape, r2, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7e59e-4ced-45f6-99e2-ec605591ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Auxiliary Function\n",
    "\n",
    "def predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model):\n",
    "    #make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    \n",
    "    #forecast\n",
    "    forecast = forecast_values(testY, look_back, horizon, model)\n",
    "    \n",
    "    #invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform(trainY)\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform(testY)\n",
    "    forecast = scaler.inverse_transform(forecast)\n",
    "    \n",
    "    #calculate all metrics for test set\n",
    "    test_rmse, test_mse, test_mae, test_mape, test_r2, test_accuracy, test_precision, test_recall, test_f1 = calculate_all_metrics(testY, testPredict)\n",
    "    \n",
    "    print('Evaluation:')\n",
    "    print('- Regression:')\n",
    "    print(f'RMSE: {test_rmse:.2f}')\n",
    "    print(f'MSE: {test_mse:.2f}')\n",
    "    print(f'MAE: {test_mae:.2f}')\n",
    "    print(f'MAPE: {test_mape:.2f}%')\n",
    "    print(f'RÂ²: {test_r2:.2f}')\n",
    "    print('- Classification:')\n",
    "    print(f'Accuracy: {test_accuracy:.2f}%')\n",
    "    print(f'Precision: {test_precision:.2f}%')\n",
    "    print(f'Recall: {test_recall:.2f}%')\n",
    "    print(f'F1-Score: {test_f1:.2f}%')\n",
    "    \n",
    "    #plot predictions\n",
    "    if plot_predictions==True: \n",
    "        #shift train predictions for plotting\n",
    "        trainPredictPlot = np.empty_like(data)\n",
    "        trainPredictPlot[:, :] = np.nan\n",
    "        trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "        \n",
    "        #shift test predictions for plotting\n",
    "        testPredictPlot = np.empty_like(data)\n",
    "        testPredictPlot[:, :] = np.nan\n",
    "        testPredictPlot[len(trainPredict)+(look_back*2)+1:len(data)-1, :] = testPredict\n",
    "        \n",
    "        #shift forecast for plotting\n",
    "        forecastPlot = np.empty_like(pd.concat([data, pd.DataFrame(forecast)]))\n",
    "        forecastPlot[:, :] = np.nan\n",
    "        forecastPlot[len(data):len(forecastPlot),:] = forecast\n",
    "        \n",
    "        #plot baseline, predictions and forecast\n",
    "        plt.figure(figsize=(15,7))\n",
    "        plt.plot(scaler.inverse_transform(data), label='real')\n",
    "        plt.plot(trainPredictPlot, label='train set prediction')\n",
    "        plt.plot(testPredictPlot, label='test set prediction')\n",
    "        plt.plot(forecastPlot, label='forecast')\n",
    "        plt.legend()\n",
    "        plt.title('Price Predictions and Forecast')\n",
    "        plt.show()\n",
    "    \n",
    "    return (test_rmse, test_mse, test_mae, test_mape, test_r2, test_accuracy, test_precision, test_recall, test_f1, \n",
    "            testPredict.flatten(), testY.flatten(), forecast.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb556faa-226f-48d4-a900-4799885a6ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title Train and Predict\n",
    "\n",
    "def model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False):\n",
    "    #reshape\n",
    "    trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "    \n",
    "    #create the network\n",
    "    input_layer = Input(shape=(trainX.shape[1], trainX.shape[2]))\n",
    "    x = LSTM(16, activation='relu')(input_layer)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    model_instance = Model(inputs=input_layer, outputs=output)\n",
    "    model_instance.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    #fit\n",
    "    model_instance.fit(trainX, trainY, epochs=nepochs, batch_size=1, verbose=1)\n",
    "    \n",
    "    #predict, forecast and plot\n",
    "    results = predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model_instance)\n",
    "    \n",
    "    return results\n",
    "\n",
    "scaler, data, train, test = read_prepare_data('AAPL')\n",
    "rmse, mse, mae, mape, r2, accuracy, precision, recall, f1, _, _, _ = model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16401d60-faa0-42dd-8639-968b149e59ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Evaluate each Symbol\n",
    "\n",
    "results = []\n",
    "risk_return = []\n",
    "symbols = stock_data[\"Symbol\"].unique()\n",
    "\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        scaler, data, train, test = read_prepare_data(symbol)\n",
    "        \n",
    "        full_results = model(data, train, test, look_back=30, nepochs=50, horizon=7, plot_predictions=False)\n",
    "        \n",
    "        (rmse, mse, mae, mape, r2, accuracy, precision, recall, f1, \n",
    "         test_predictions, test_actual, forecast_values) = full_results\n",
    "        \n",
    "        \n",
    "        results.append({\n",
    "            \"Symbol\": symbol,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MSE\": mse,\n",
    "            \"MAE\": mae,\n",
    "            \"MAPE\": mape,\n",
    "            \"R2\": r2,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1\": f1\n",
    "        })\n",
    "        \n",
    "        risk_return.append({\n",
    "            \"Symbol\": symbol,\n",
    "            \"Test Predictions\": test_predictions,\n",
    "            \"Test Actual\": test_actual,\n",
    "            \"Forecast Values\": forecast_values\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {symbol}: {e}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "risk_return_df = pd.DataFrame(risk_return)\n",
    "results_df.to_csv('/Users/pedroalexleite/Desktop/Tese/Dados/final_results.csv', index=False)\n",
    "risk_return_df.to_csv('/Users/pedroalexleite/Desktop/Tese/Dados/risk_return.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af14879b-0c66-4a39-ad19-c4bba00bd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title DUMMY DFs !!!!!!!!!!!!!!!!!!\n",
    "\n",
    "data = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/dataset4.csv')\n",
    "symbols = data[\"Symbol\"].unique()\n",
    "\n",
    "np.random.seed(42)  \n",
    "\n",
    "dummy_1 = {\n",
    "    \"Symbol\": symbols,\n",
    "    \"RMSE\": np.random.uniform(0.5, 2.0, len(symbols)),\n",
    "    \"MSE\": np.random.uniform(0.2, 4.0, len(symbols)),\n",
    "    \"MAE\": np.random.uniform(0.3, 1.5, len(symbols)),\n",
    "    \"MAPE\": np.random.uniform(5, 20, len(symbols)),\n",
    "    \"R2\": np.random.uniform(0.0, 1.0, len(symbols)),\n",
    "    \"Accuracy\": np.random.uniform(0.5, 1.0, len(symbols)),\n",
    "    \"Precision\": np.random.uniform(0.5, 1.0, len(symbols)),\n",
    "    \"Recall\": np.random.uniform(0.5, 1.0, len(symbols)),\n",
    "    \"F1\": np.random.uniform(0.5, 1.0, len(symbols)),\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(dummy_1)\n",
    "results_df.to_csv('/Users/pedroalexleite/Desktop/Tese/Dados/final_results.csv', index=False)\n",
    "\n",
    "dummy_2 = {\n",
    "    \"Symbol\": symbols,\n",
    "    \"Test Predictions\": [np.random.uniform(50, 300, 335) for _ in range(len(symbols))],\n",
    "    \"Test Actual\": [np.random.uniform(50, 300, 335) for _ in range(len(symbols))],    \n",
    "    \"Forecast Values\": [np.random.uniform(50, 300, 7) for _ in range(len(symbols))], \n",
    "}\n",
    "\n",
    "risk_return_df = pd.DataFrame(dummy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70614413-cae8-430a-9ca0-7c64cce21534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Risk-Return Calculation\n",
    "\n",
    "def calculate_risk_return_tradeoff(predicted_prices, actual_prices=None):\n",
    "    predicted_returns = np.diff(predicted_prices) / predicted_prices[:-1]\n",
    "    expected_return = np.mean(predicted_returns)\n",
    "    risk = np.std(predicted_returns)\n",
    "    \n",
    "    return expected_return, risk\n",
    "\n",
    "daily_returns = []\n",
    "daily_risks = []\n",
    "\n",
    "for idx, row in risk_return_df.iterrows():\n",
    "    try:\n",
    "        test_predictions = eval(row['Test Predictions']) if isinstance(row['Test Predictions'], str) else row['Test Predictions']\n",
    "        expected_return, risk = calculate_risk_return_tradeoff(test_predictions)\n",
    "        daily_returns.append(expected_return)\n",
    "        daily_risks.append(risk)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row['Symbol']}: {e}\")\n",
    "        daily_returns.append(np.nan)\n",
    "        daily_risks.append(np.nan)\n",
    "\n",
    "risk_return_df_2 = pd.DataFrame({\n",
    "    'Symbol': risk_return_df['Symbol'],\n",
    "    'Daily Return': daily_returns,\n",
    "    'Daily Risk': daily_risks\n",
    "})\n",
    "\n",
    "sp500 = pd.read_csv(\"/Users/pedroalexleite/Desktop/Tese/Dados/sp500.csv\")\n",
    "merged_df_3 = pd.merge(risk_return_df_2, sp500[['Symbol', 'Sector']], on='Symbol', how='left')\n",
    "merged_df_3.to_csv('/Users/pedroalexleite/Desktop/Tese/Dados/risk_return.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
