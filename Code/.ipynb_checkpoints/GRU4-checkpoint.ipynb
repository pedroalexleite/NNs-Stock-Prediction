{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3058ab-b2ae-47e2-a532-fb1c4c668472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, GRU, Bidirectional, Input, Attention, Concatenate, GlobalAveragePooling1D, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adagrad, Adadelta\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, Huber\n",
    "from tensorflow.keras.backend import sqrt, mean, square\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33e7e57-e569-4116-893d-0e980cad3ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low  Volume     Close\n",
      "Date                                                      \n",
      "2021-11-01 -0.345579 -0.377519 -0.335396    -1.0 -0.329693\n",
      "2021-11-02 -0.354977 -0.324439 -0.311489    -1.0 -0.300014\n",
      "2021-11-03 -0.305710 -0.313085 -0.278582    -1.0 -0.258855\n",
      "2021-11-04 -0.271821 -0.300028 -0.255520    -1.0 -0.273695\n",
      "2021-11-05 -0.262993 -0.306557 -0.271832    -1.0 -0.264735\n",
      "Index(['2021-11-01', '2021-11-02', '2021-11-03', '2021-11-04', '2021-11-05',\n",
      "       '2021-11-06', '2021-11-07', '2021-11-08', '2021-11-09', '2021-11-10',\n",
      "       ...\n",
      "       '2024-10-23', '2024-10-24', '2024-10-25', '2024-10-26', '2024-10-27',\n",
      "       '2024-10-28', '2024-10-29', '2024-10-30', '2024-10-31', '2024-11-01'],\n",
      "      dtype='object', name='Date', length=1097)\n",
      "Index(['Open', 'High', 'Low', 'Volume', 'Close'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#@tile Read and Prepare Data\n",
    "\n",
    "def read_prepare_data(symbol):\n",
    "    #read\n",
    "    data = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/dataset4.csv')\n",
    "    train =  pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/train.csv')\n",
    "    test =  pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/test.csv')\n",
    "    \n",
    "    #we're going to use only one symbol\n",
    "    data = data[data['Symbol'] == symbol].copy()\n",
    "    train = train[train['Symbol'] == symbol].copy()\n",
    "    test = test[test['Symbol'] == symbol].copy()\n",
    "    \n",
    "    #we're going to use only the price variable\n",
    "    data = data[['Date', 'Simple Moving Average', 'Moving Average Convergence Divergence', 'Average Directional Movement Index', \n",
    "                 'Middle Band', 'Average True Range', 'Relative Strength Index', 'Stochastic Oscillator K', 'Commodity Channel Index',\n",
    "                 'Rate of Change', 'On Balance Volume', 'Chaikin AD Line', 'Chaikin AD Oscillator', 'Parabolic SAR', 'Linear Regression',\n",
    "                 'Aroon Oscillator', 'Money Flow Index', 'Close']].copy()\n",
    "    train = train[['Date', 'Simple Moving Average', 'Moving Average Convergence Divergence', 'Average Directional Movement Index', \n",
    "                 'Middle Band', 'Average True Range', 'Relative Strength Index', 'Stochastic Oscillator K', 'Commodity Channel Index',\n",
    "                 'Rate of Change', 'On Balance Volume', 'Chaikin AD Line', 'Chaikin AD Oscillator', 'Parabolic SAR', 'Linear Regression',\n",
    "                 'Aroon Oscillator', 'Money Flow Index', 'Close']].copy()\n",
    "    test = test[['Date', 'Simple Moving Average', 'Moving Average Convergence Divergence', 'Average Directional Movement Index', \n",
    "                 'Middle Band', 'Average True Range', 'Relative Strength Index', 'Stochastic Oscillator K', 'Commodity Channel Index',\n",
    "                 'Rate of Change', 'On Balance Volume', 'Chaikin AD Line', 'Chaikin AD Oscillator', 'Parabolic SAR', 'Linear Regression',\n",
    "                 'Aroon Oscillator', 'Money Flow Index', 'Close']].copy()\n",
    "    \n",
    "    #set date as index\n",
    "    data.set_index('Date', inplace=True)\n",
    "    train.set_index('Date', inplace=True)\n",
    "    test.set_index('Date', inplace=True)\n",
    "\n",
    "    #normalize\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)\n",
    "    test = pd.DataFrame(scaler.transform(test), columns=test.columns, index=test.index)\n",
    "    data = pd.DataFrame(scaler.transform(data), columns=data.columns, index=data.index) \n",
    "\n",
    "    return scaler, data, train, test\n",
    "\n",
    "scaler, data, train, test = read_prepare_data('AAPL')\n",
    "\n",
    "#verify\n",
    "#print(data.head())\n",
    "#print(data.index)   \n",
    "#print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb0801a-7545-4ac0-97b0-b4c59ad80bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create Dataset\n",
    "\n",
    "def create_dataset(dataframe, look_back):\n",
    "    dataset = dataframe.values\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, -1]) \n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2f89fe-3df0-45e2-bc20-f099bc840ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Reshape\n",
    "\n",
    "def reshape(train, test, look_back):\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c430f611-2b9b-409f-8c29-910f09a806de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Forecast\n",
    "\n",
    "def forecast_values(testY, look_back, horizon, model, last_sequence):\n",
    "    testY_copy = testY.copy()\n",
    "    last_sequence = last_sequence.copy()\n",
    "    \n",
    "    for val in range(0, horizon+1):\n",
    "        a = last_sequence[-look_back:]\n",
    "        a = np.reshape(a, (1, look_back, last_sequence.shape[-1]))\n",
    "        a_predict = model.predict(a, verbose=0)[0]\n",
    "        new_row = last_sequence[-1:].copy()\n",
    "        new_row[0, -1] = a_predict  \n",
    "        last_sequence = np.vstack([last_sequence, new_row])\n",
    "        testY_copy = np.append(testY_copy, a_predict)\n",
    "    \n",
    "    forecast = testY_copy[len(testY)+1:]\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99dca1fe-b873-4187-9e43-188106065206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Auxiliary Function \n",
    "\n",
    "def predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model):\n",
    "    #make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    \n",
    "    #forecast (get the last sequence from testX for forecasting)\n",
    "    last_sequence = testX[-1]\n",
    "    forecast = forecast_values(testY, look_back, horizon, model, last_sequence)\n",
    "\n",
    "    #invert predictions - need to handle multivariate data\n",
    "    dummy = np.zeros((len(trainPredict), train.shape[1]))\n",
    "    dummy[:, -1] = trainPredict.flatten() \n",
    "    trainPredict = scaler.inverse_transform(dummy)[:, -1]\n",
    "    \n",
    "    dummy = np.zeros((len(trainY), train.shape[1]))\n",
    "    dummy[:, -1] = trainY.flatten()\n",
    "    trainY = scaler.inverse_transform(dummy)[:, -1]\n",
    "    \n",
    "    dummy = np.zeros((len(testPredict), train.shape[1]))\n",
    "    dummy[:, -1] = testPredict.flatten()\n",
    "    testPredict = scaler.inverse_transform(dummy)[:, -1]\n",
    "    \n",
    "    dummy = np.zeros((len(testY), train.shape[1]))\n",
    "    dummy[:, -1] = testY.flatten()\n",
    "    testY = scaler.inverse_transform(dummy)[:, -1]\n",
    "    \n",
    "    dummy = np.zeros((len(forecast), train.shape[1]))\n",
    "    dummy[:, -1] = forecast.flatten()\n",
    "    forecast = scaler.inverse_transform(dummy)[:, -1]\n",
    "\n",
    "    #calculate root mean squared error\n",
    "    trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = np.sqrt(mean_squared_error(testY, testPredict))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "    #plot predictions\n",
    "    if plot_predictions==True: \n",
    "        # Get the original Close prices\n",
    "        original_data = scaler.inverse_transform(data)[:, -1]\n",
    "        \n",
    "        #shift train predictions for plotting\n",
    "        trainPredictPlot = np.empty_like(original_data)\n",
    "        trainPredictPlot[:] = np.nan\n",
    "        trainPredictPlot[look_back:len(trainPredict)+look_back] = trainPredict\n",
    "        \n",
    "        #shift test predictions for plotting\n",
    "        testPredictPlot = np.empty_like(original_data)\n",
    "        testPredictPlot[:] = np.nan\n",
    "        testPredictPlot[len(trainPredict)+(look_back*2)+1:len(original_data)-1] = testPredict\n",
    "        \n",
    "        #shift forecast for plotting\n",
    "        forecastPlot = np.empty((len(original_data) + len(forecast),))\n",
    "        forecastPlot[:] = np.nan\n",
    "        forecastPlot[len(original_data):] = forecast\n",
    "        \n",
    "        #plot baseline, predictions and forecast\n",
    "        plt.figure(figsize=(15,7))\n",
    "        plt.plot(original_data, label='actual')\n",
    "        plt.plot(trainPredictPlot, label='train set')\n",
    "        plt.plot(testPredictPlot, label='test set')\n",
    "        plt.plot(forecastPlot, label='forecast')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24840eb-06a1-4895-bd73-f004098be0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Models\n",
    "\n",
    "def list_models(look_back, trainX):\n",
    "    layers = [1, 2]\n",
    "    neurons = [8, 16, 32, 64, 128, 256, 512]\n",
    "    dropouts = [0.1, 0.2]\n",
    "    models = []\n",
    "    configurations = []\n",
    "    \n",
    "    for num_layers in layers:\n",
    "        for num_neurons in neurons:\n",
    "            for dropout_rate in dropouts:\n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(GRU(num_neurons, input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=(num_layers > 1)))\n",
    "                model.add(Dropout(dropout_rate))\n",
    "                \n",
    "                for layer_idx in range(1, num_layers):\n",
    "                    model.add(GRU(num_neurons, return_sequences=(layer_idx < num_layers - 1)))\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "                \n",
    "                model.add(Dense(1))\n",
    "                \n",
    "                model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "                \n",
    "                models.append(model)\n",
    "                configurations.append({\n",
    "                    \"layers\": num_layers,\n",
    "                    \"neurons\": num_neurons,\n",
    "                    \"dropout\": dropout_rate\n",
    "                })\n",
    "    \n",
    "    return models, configurations\n",
    "\n",
    "look_back = 60\n",
    "trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "models, configurations = list_models(look_back, trainX)\n",
    "\n",
    "print(\"Configurations:\")\n",
    "for idx, config in enumerate(configurations, start=1):\n",
    "    print(f\"Model {idx}: Layers={config['layers']}, Neurons={config['neurons']}, Dropout={config['dropout']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83eaee-72ef-4e0c-a403-0bfc47aeaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Train and Predict (Find the Optimal Model)\n",
    "\n",
    "def optimal_model(models, configurations, data, train, test, look_back=1, nepochs=10, horizon=10, plot_predictions=False):\n",
    "    results = []\n",
    "\n",
    "    for idx, (model, config) in enumerate(zip(models, configurations), start=1):\n",
    "        print(f\"Training Model {idx}: Layers={config['layers']}, Neurons={config['neurons']}, Dropout={config['dropout']}\")\n",
    "        \n",
    "        #reshape\n",
    "        trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "\n",
    "        #fit\n",
    "        model.fit(trainX, trainY, epochs=nepochs, batch_size=1, verbose=1)\n",
    "\n",
    "        #predict, foecast and plot\n",
    "        testScore =  predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model)\n",
    "\n",
    "        #append results\n",
    "        results.append({\n",
    "            \"model_index\": idx,\n",
    "            \"configuration\": config,\n",
    "            \"test_score\": testScore\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_average_results(models, configurations, data, train, test, look_back=1, nepochs=10, horizon=10, runs=10):\n",
    "    all_results = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print(f\"Run {run + 1}/{runs}\")\n",
    "        results = optimal_model(models, configurations, data, train, test, look_back, nepochs, horizon)\n",
    "        all_results.extend(results)\n",
    "\n",
    "    #aggregate results by model\n",
    "    average_results = {}\n",
    "    for result in all_results:\n",
    "        model_idx = result[\"model_index\"]\n",
    "        if model_idx not in average_results:\n",
    "            average_results[model_idx] = {\n",
    "                \"configuration\": result[\"configuration\"],\n",
    "                \"test_scores\": []\n",
    "            }\n",
    "        average_results[model_idx][\"test_scores\"].append(result[\"test_score\"])\n",
    "\n",
    "    #calculate average train and test scores\n",
    "    for model_idx, scores in average_results.items():\n",
    "        test_avg = np.mean(scores[\"test_scores\"])\n",
    "        average_results[model_idx][\"test_score_avg\"] = test_avg\n",
    "\n",
    "    return average_results\n",
    "\n",
    "models, configurations= list_models(60, trainX)\n",
    "average_results = calculate_average_results(models, configurations, data, train, test, look_back=60, nepochs=50, horizon=10, runs=10)\n",
    "\n",
    "for model_idx, scores in average_results.items():\n",
    "    print(f\"Model {model_idx}:\")\n",
    "    print(f\"  Configuration: {scores['configuration']}\")\n",
    "    print(f\"  Average Test Score: {scores['test_score_avg']:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae5b4e84-65ec-4571-9d9e-1fcffeea8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Train and Predict\n",
    "\n",
    "def model(data, train, test, look_back=1, nepochs=10, horizon=10, plot_predictions=False):\n",
    "    #reshape\n",
    "    trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "\n",
    "    #create the network\n",
    "    model = Sequential()\n",
    "    model.add(GRU(16, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #model.summary()\n",
    "\n",
    "    #fit\n",
    "    model.fit(trainX, trainY, epochs=nepochs, batch_size=1, verbose=1)\n",
    "\n",
    "    #predict, forecast and plot\n",
    "    testScore = predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model)\n",
    "    \n",
    "    return testScore\n",
    "\n",
    "#model(data, train, test, look_back=60, nepochs=50, horizon=10, plot_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c25bc2-6ed0-458a-a534-0044d6fded3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run the Model Several Times\n",
    "\n",
    "n_runs = 50\n",
    "rmse_results = []\n",
    "for i in range(n_runs):\n",
    "    print(f\"Running iteration {i+1}/{n_runs}...\")\n",
    "    test_rmse = model(data, train, test, look_back=60, nepochs=50, horizon=10, plot_predictions=False)  \n",
    "    rmse_results.append(test_rmse)\n",
    "\n",
    "rmse_results = np.array(rmse_results)\n",
    "print(\"All RMSE results:\", rmse_results)\n",
    "print(f\"Mean RMSE: {np.mean(rmse_results):.2f}\")\n",
    "print(f\"Standard Deviation: {np.std(rmse_results):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
