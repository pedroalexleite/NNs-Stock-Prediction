{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a899449-6b60-4e4e-a1c9-bc3d4d91a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Requirements\n",
    "\n",
    "!brew install ta-lib -q\n",
    "\n",
    "!pip install TA-Lib -q\n",
    "\n",
    "#!pip install yfinance -q\n",
    "\n",
    "#!pip install fredapi pandas_datareader -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8940e9de-0579-4bd4-a35e-c07df061c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "import yfinance as yf\n",
    "from fredapi import Fred\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8450d507-7caf-41d9-94f5-35d00d27516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of               Date    Open    High     Low   Close     Volume Symbol\n",
      "0       2020-06-01   88.04   89.98   87.94   89.91  2482239.0      A\n",
      "1       2020-06-02   90.00   90.63   89.11   90.29  1682945.0      A\n",
      "2       2020-06-03   90.65   91.14   90.26   90.49  1382690.0      A\n",
      "3       2020-06-04   89.82   91.74   89.82   91.14  2227462.0      A\n",
      "4       2020-06-05   92.13   93.04   90.09   90.38  2844690.0      A\n",
      "...            ...     ...     ...     ...     ...        ...    ...\n",
      "818082  2025-05-26  160.55  163.06  160.14  162.58  2732205.0    ZTS\n",
      "818083  2025-05-27  164.00  166.89  163.83  166.26  2323105.0    ZTS\n",
      "818084  2025-05-28  166.16  166.65  164.52  165.40  1723859.0    ZTS\n",
      "818085  2025-05-29  165.92  167.79  165.11  167.14  2450453.0    ZTS\n",
      "818086  2025-05-30  166.42  169.79  165.34  168.63  5467823.0    ZTS\n",
      "\n",
      "[818087 rows x 7 columns]>\n",
      "(818087, 7)\n",
      "Date       object\n",
      "Open      float64\n",
      "High      float64\n",
      "Low       float64\n",
      "Close     float64\n",
      "Volume    float64\n",
      "Symbol     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#@title Read Dataset\n",
    "\n",
    "stock_data = pd.read_csv(\"/Users/pedroalexleite/Desktop/Tese/Dados/dataset2.csv\")\n",
    "\n",
    "print(stock_data.head)\n",
    "print(stock_data.shape)\n",
    "print(stock_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7c2b0e3-0626-4b6d-8423-8d58105f6b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/b9bk135x3gd6hxg4hr0846t80000gn/T/ipykernel_10831/367601804.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stock_data = stock_data.groupby('Symbol', group_keys=False).apply(calculate_indicators)\n"
     ]
    }
   ],
   "source": [
    "#@title Add Technical Indicators\n",
    "\n",
    "def calculate_indicators(group):\n",
    "    close = group['Close'].values\n",
    "    high = group['High'].values\n",
    "    low = group['Low'].values\n",
    "    open_ = group['Open'].values\n",
    "    volume = group['Volume'].values\n",
    "\n",
    "    #trend\n",
    "    group['SMA'] = talib.SMA(close, timeperiod=14)\n",
    "    group['EMA'] = talib.EMA(close, timeperiod=14)\n",
    "    macd, macdsignal, macdhist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    group['MACD'] = macd\n",
    "    group['ADX'] = talib.ADX(high, low, close, timeperiod=14)\n",
    "    group['PSAR'] = talib.SAR(high, low, acceleration=0.02, maximum=0.2)\n",
    "\n",
    "    #momentum\n",
    "    group['RSI'] = talib.RSI(close, timeperiod=14)\n",
    "    group['ROC'] = talib.ROC(close, timeperiod=10)\n",
    "    group['SOK'] = talib.STOCH(high, low, close)[0] \n",
    "    group['MOM'] = talib.MOM(close, timeperiod=10)\n",
    "    group['WILLR'] = talib.WILLR(high, low, close, timeperiod=14)\n",
    "    group['TRIX'] = talib.TRIX(close, timeperiod=15)\n",
    "    group['CMO'] = talib.CMO(close, timeperiod=14)\n",
    "\n",
    "    #volatility\n",
    "    upperband, middleband, lowerband = talib.BBANDS(close, timeperiod=20)\n",
    "    group['BB_upper'] = upperband\n",
    "    group['BB_middle'] = middleband\n",
    "    group['BB_lower'] = lowerband\n",
    "    group['SD'] = talib.STDDEV(close, timeperiod=14, nbdev=1)\n",
    "\n",
    "    #volume\n",
    "    group['OBV'] = talib.OBV(close, volume)\n",
    "    group['AD'] = talib.AD(high, low, close, volume)\n",
    "    group['MFI'] = talib.MFI(high, low, close, volume, timeperiod=14)\n",
    "\n",
    "    #statistical\n",
    "    group['CCI'] = talib.CCI(high, low, close, timeperiod=14)\n",
    "    group['BOP'] = talib.BOP(open_, high, low, close)\n",
    "\n",
    "    return group\n",
    "\n",
    "stock_data = stock_data.groupby('Symbol', group_keys=False).apply(calculate_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e64ec97f-e0c1-42bf-9984-0f648351ea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched TBL (TB3MS)\n",
      "Successfully fetched LTY (GS10)\n",
      "Successfully fetched TMS (T10Y3M)\n",
      "Successfully fetched DFY (BAA10Y)\n",
      "Successfully fetched RGDPG (GDPC1)\n",
      "Successfully fetched REG_BASE (CP)\n",
      "Successfully fetched RNCFG_BASE (CNCF)\n",
      "Successfully fetched CPI (CPIAUCSL)\n"
     ]
    }
   ],
   "source": [
    "#@title Add Macro-Economic Indicators \n",
    "\n",
    "fred = Fred(api_key='d5b976d8228df365dceb5f0d8f0d9adb')\n",
    "\n",
    "fred_series = {\n",
    "    'TBL': 'TB3MS',          # 3-Month Treasury Bill Rate\n",
    "    'LTY': 'GS10',           # 10-Year Treasury Rate\n",
    "    'TMS': 'T10Y3M',         # Term Spread\n",
    "    'DFY': 'BAA10Y',         # Default Yield Spread\n",
    "    'RGDPG': 'GDPC1',        # Real GDP (for growth calculation)\n",
    "    'REG_BASE': 'CP',        # Corporate Profits (for REG calculation)\n",
    "    'RNCFG_BASE': 'CNCF',    # Corporate Net Cash Flow with IVA (alternative series)\n",
    "    'CPI': 'CPIAUCSL'        # Consumer Price Index (for real adjustments)\n",
    "}\n",
    "\n",
    "#fetch all FRED data\n",
    "fred_dfs = []\n",
    "for name, series_id in fred_series.items():\n",
    "    try:\n",
    "        data = fred.get_series(series_id)\n",
    "        df = data.to_frame(name)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        fred_dfs.append(df)\n",
    "        print(f\"Successfully fetched {name} ({series_id})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {name} ({series_id}): {e}\")\n",
    "\n",
    "#dombine all FRED data\n",
    "macro_data = pd.concat(fred_dfs, axis=1)\n",
    "macro_data = macro_data.sort_index().ffill()\n",
    "\n",
    "#calculate derived variables\n",
    "def calculate_derived_variables(macro_data):    \n",
    "    #RGDPG\n",
    "    if 'RGDPG' in macro_data.columns:\n",
    "        macro_data['RGDPG'] = macro_data['RGDPG'].pct_change(periods=4) * 100  # YoY growth\n",
    "    \n",
    "    #LTR\n",
    "    if 'LTY' in macro_data.columns:\n",
    "        macro_data['LTR'] = -macro_data['LTY'].diff() * 8 \n",
    "    \n",
    "    #DFR\n",
    "    if 'DFY' in macro_data.columns:\n",
    "        macro_data['DFR'] = macro_data['DFY'].diff()\n",
    "    \n",
    "    #REG\n",
    "    if 'REG_BASE' in macro_data.columns and 'CPI' in macro_data.columns:\n",
    "        real_earnings = macro_data['REG_BASE'] / (macro_data['CPI'] / 100)\n",
    "        macro_data['REG'] = real_earnings.pct_change(periods=4) * 100\n",
    "    \n",
    "    #RNCFG\n",
    "    if 'RNCFG_BASE' in macro_data.columns and 'CPI' in macro_data.columns:\n",
    "        real_cash_flow = macro_data['RNCFG_BASE'] / (macro_data['CPI'] / 100)\n",
    "        macro_data['RNCFG'] = real_cash_flow.pct_change(periods=4) * 100\n",
    "    \n",
    "    return macro_data\n",
    "\n",
    "#apply calculations\n",
    "macro_data = calculate_derived_variables(macro_data)\n",
    "\n",
    "#select final variables \n",
    "available_vars = ['TBL', 'LTY', 'TMS', 'DFY', 'RGDPG', 'LTR', 'DFR', 'REG', 'RNCFG']\n",
    "final_macro_vars = [var for var in available_vars if var in macro_data.columns]\n",
    "macro_data_final = macro_data[final_macro_vars].copy()\n",
    "\n",
    "#merge with stock data\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "stock_data = stock_data.merge(macro_data_final, how='left', left_on='Date', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcb2e8-0941-47f1-8bb6-1c8db5770272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/818087 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_KEY = \"IXXBASGLN6Z323SB\"\n",
    "\n",
    "def get_alpha_vantage_dividends(symbol):\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&apikey={API_KEY}&outputsize=full'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    if \"Time Series (Daily)\" not in data:\n",
    "        print(f\"Error fetching data for {symbol}: {data.get('Error Message', 'No Time Series')}\")\n",
    "        return None\n",
    "    \n",
    "    ts = data[\"Time Series (Daily)\"]\n",
    "    df = pd.DataFrame.from_dict(ts, orient='index')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    # Dividend amount column (daily)\n",
    "    df['dividend_amount'] = df['7. dividend amount'].astype(float)\n",
    "    df = df[['dividend_amount']]\n",
    "    # Keep only days with dividend > 0\n",
    "    df = df[df['dividend_amount'] > 0]\n",
    "    return df\n",
    "\n",
    "# Example structure of stock_data: must have 'Symbol', 'Date', and 'Close'\n",
    "# stock_data = pd.DataFrame({\n",
    "#    'Symbol': ['AAPL', 'AAPL', 'MSFT', 'MSFT'],\n",
    "#    'Date': ['2021-01-15', '2021-04-15', '2021-01-15', '2021-04-15'],\n",
    "#    'Close': [130, 135, 220, 230]\n",
    "# })\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "# Cache dividend data per symbol\n",
    "dividends_cache = {}\n",
    "\n",
    "def get_latest_dividend_av(symbol, date):\n",
    "    if symbol not in dividends_cache:\n",
    "        div_df = get_alpha_vantage_dividends(symbol)\n",
    "        if div_df is None:\n",
    "            dividends_cache[symbol] = pd.Series(dtype=float)\n",
    "        else:\n",
    "            dividends_cache[symbol] = div_df['dividend_amount']\n",
    "    divs = dividends_cache[symbol]\n",
    "    div_before_date = divs[divs.index <= date]\n",
    "    if div_before_date.empty:\n",
    "        return 0.0\n",
    "    return div_before_date.iloc[-1]\n",
    "\n",
    "dp_values = []\n",
    "for idx, row in tqdm(stock_data.iterrows(), total=stock_data.shape[0]):\n",
    "    symbol = row['Symbol']\n",
    "    date = row['Date']\n",
    "    price = row['Close']\n",
    "    dividend = get_latest_dividend_av(symbol, date)\n",
    "    dp = dividend / price if price > 0 else np.nan\n",
    "    dp_values.append(dp)\n",
    "\n",
    "stock_data['D/P'] = dp_values\n",
    "\n",
    "print(stock_data[['Symbol', 'Date', 'Close', 'D/P']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ae90ee8-67bb-49ec-9a66-9c181d382d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Save CSV File\n",
    "\n",
    "stock_data.to_csv('/Users/pedroalexleite/Desktop/Tese/Dados/dataset3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
