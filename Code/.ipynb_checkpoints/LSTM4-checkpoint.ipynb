{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3058ab-b2ae-47e2-a532-fb1c4c668472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 02:08:45.398202: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#@title Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, GRU, Bidirectional, Input, Attention, Concatenate, GlobalAveragePooling1D, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adagrad, Adadelta\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, Huber\n",
    "from tensorflow.keras.backend import sqrt, mean, square\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33e7e57-e569-4116-893d-0e980cad3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tile Read and Prepare Data\n",
    "\n",
    "def read_prepare_data(symbol):\n",
    "    #read\n",
    "    data = pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/dataset4.csv')\n",
    "    train =  pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/train.csv')\n",
    "    test =  pd.read_csv('/Users/pedroalexleite/Desktop/Tese/Dados/test.csv')\n",
    "    \n",
    "    #we're going to use only one symbol\n",
    "    data = data[data['Symbol'] == symbol].copy()\n",
    "    train = train[train['Symbol'] == symbol].copy()\n",
    "    test = test[test['Symbol'] == symbol].copy()\n",
    "    \n",
    "    #we're going to use only the price variable\n",
    "    data = data[['Date', 'Simple Moving Average', 'Moving Average Convergence Divergence', 'Average Directional Movement Index', \n",
    "                 'Middle Band', 'Average True Range', 'Relative Strength Index', 'Stochastic Oscillator K', 'Commodity Channel Index',\n",
    "                 'Rate of Change', 'On Balance Volume', 'Chaikin AD Line', 'Chaikin AD Oscillator', 'Parabolic SAR', 'Linear Regression',\n",
    "                 'Aroon Oscillator', 'Money Flow Index', 'Close']].copy()\n",
    "    train = train[['Date', 'Simple Moving Average', 'Moving Average Convergence Divergence', 'Average Directional Movement Index', \n",
    "                 'Middle Band', 'Average True Range', 'Relative Strength Index', 'Stochastic Oscillator K', 'Commodity Channel Index',\n",
    "                 'Rate of Change', 'On Balance Volume', 'Chaikin AD Line', 'Chaikin AD Oscillator', 'Parabolic SAR', 'Linear Regression',\n",
    "                 'Aroon Oscillator', 'Money Flow Index', 'Close']].copy()\n",
    "    test = test[['Date', 'Simple Moving Average', 'Moving Average Convergence Divergence', 'Average Directional Movement Index', \n",
    "                 'Middle Band', 'Average True Range', 'Relative Strength Index', 'Stochastic Oscillator K', 'Commodity Channel Index',\n",
    "                 'Rate of Change', 'On Balance Volume', 'Chaikin AD Line', 'Chaikin AD Oscillator', 'Parabolic SAR', 'Linear Regression',\n",
    "                 'Aroon Oscillator', 'Money Flow Index', 'Close']].copy()\n",
    "    \n",
    "    #set date as index\n",
    "    data.set_index('Date', inplace=True)\n",
    "    train.set_index('Date', inplace=True)\n",
    "    test.set_index('Date', inplace=True)\n",
    "\n",
    "    #normalize\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)\n",
    "    test = pd.DataFrame(scaler.transform(test), columns=test.columns, index=test.index)\n",
    "    data = pd.DataFrame(scaler.transform(data), columns=data.columns, index=data.index) \n",
    "\n",
    "    return scaler, data, train, test\n",
    "\n",
    "scaler, data, train, test = read_prepare_data('AAPL')\n",
    "\n",
    "#verify\n",
    "#print(data.head())\n",
    "#print(data.index)   \n",
    "#print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb0801a-7545-4ac0-97b0-b4c59ad80bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create Dataset\n",
    "\n",
    "def create_dataset(dataframe, look_back):\n",
    "    dataset = dataframe.values\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, -1]) \n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2f89fe-3df0-45e2-bc20-f099bc840ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Reshape\n",
    "\n",
    "def reshape(train, test, look_back):\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c430f611-2b9b-409f-8c29-910f09a806de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Forecast\n",
    "\n",
    "def forecast_values(testY, look_back, horizon, model, last_sequence):\n",
    "    testY_copy = testY.copy()\n",
    "    last_sequence = last_sequence.copy()\n",
    "    \n",
    "    for val in range(0, horizon+1):\n",
    "        a = last_sequence[-look_back:]\n",
    "        a = np.reshape(a, (1, look_back, last_sequence.shape[-1]))\n",
    "        a_predict = model.predict(a, verbose=0)[0]\n",
    "        new_row = last_sequence[-1:].copy()\n",
    "        new_row[0, -1] = a_predict  \n",
    "        last_sequence = np.vstack([last_sequence, new_row])\n",
    "        testY_copy = np.append(testY_copy, a_predict)\n",
    "    \n",
    "    forecast = testY_copy[len(testY)+1:]\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99dca1fe-b873-4187-9e43-188106065206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Auxiliary Function\n",
    "\n",
    "def predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model):\n",
    "    #make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    \n",
    "    #forecast (get the last sequence from testX for forecasting)\n",
    "    last_sequence = testX[-1]\n",
    "    forecast = forecast_values(testY, look_back, horizon, model, last_sequence)\n",
    "\n",
    "    #invert predictions - need to handle multivariate data\n",
    "    dummy = np.zeros((len(trainPredict), train.shape[1]))\n",
    "    dummy[:, -1] = trainPredict.flatten() \n",
    "    trainPredict = scaler.inverse_transform(dummy)[:, -1]\n",
    "    \n",
    "    dummy = np.zeros((len(trainY), train.shape[1]))\n",
    "    dummy[:, -1] = trainY.flatten()\n",
    "    trainY = scaler.inverse_transform(dummy)[:, -1]\n",
    "    \n",
    "    dummy = np.zeros((len(testPredict), train.shape[1]))\n",
    "    dummy[:, -1] = testPredict.flatten()\n",
    "    testPredict = scaler.inverse_transform(dummy)[:, -1]\n",
    "    \n",
    "    dummy = np.zeros((len(testY), train.shape[1]))\n",
    "    dummy[:, -1] = testY.flatten()\n",
    "    testY = scaler.inverse_transform(dummy)[:, -1]\n",
    "    \n",
    "    dummy = np.zeros((len(forecast), train.shape[1]))\n",
    "    dummy[:, -1] = forecast.flatten()\n",
    "    forecast = scaler.inverse_transform(dummy)[:, -1]\n",
    "\n",
    "    #calculate root mean squared error\n",
    "    trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = np.sqrt(mean_squared_error(testY, testPredict))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "    #plot predictions\n",
    "    if plot_predictions==True: \n",
    "        # Get the original Close prices\n",
    "        original_data = scaler.inverse_transform(data)[:, -1]\n",
    "        \n",
    "        #shift train predictions for plotting\n",
    "        trainPredictPlot = np.empty_like(original_data)\n",
    "        trainPredictPlot[:] = np.nan\n",
    "        trainPredictPlot[look_back:len(trainPredict)+look_back] = trainPredict\n",
    "        \n",
    "        #shift test predictions for plotting\n",
    "        testPredictPlot = np.empty_like(original_data)\n",
    "        testPredictPlot[:] = np.nan\n",
    "        testPredictPlot[len(trainPredict)+(look_back*2)+1:len(original_data)-1] = testPredict\n",
    "        \n",
    "        #shift forecast for plotting\n",
    "        forecastPlot = np.empty((len(original_data) + len(forecast),))\n",
    "        forecastPlot[:] = np.nan\n",
    "        forecastPlot[len(original_data):] = forecast\n",
    "        \n",
    "        #plot baseline, predictions and forecast\n",
    "        plt.figure(figsize=(15,7))\n",
    "        plt.plot(original_data, label='actual')\n",
    "        plt.plot(trainPredictPlot, label='train set')\n",
    "        plt.plot(testPredictPlot, label='test set')\n",
    "        plt.plot(forecastPlot, label='forecast')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24840eb-06a1-4895-bd73-f004098be0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations:\n",
      "Model 1: Layers=1, Neurons=512, Dropout=0.1\n",
      "Model 2: Layers=1, Neurons=1024, Dropout=0.1\n",
      "Model 3: Layers=1, Neurons=2048, Dropout=0.1\n",
      "Model 4: Layers=2, Neurons=512, Dropout=0.1\n",
      "Model 5: Layers=2, Neurons=1024, Dropout=0.1\n",
      "Model 6: Layers=2, Neurons=2048, Dropout=0.1\n"
     ]
    }
   ],
   "source": [
    "#@title Models\n",
    "\n",
    "def list_models(look_back, trainX):\n",
    "    layers = [1, 2]\n",
    "    neurons = [8, 16, 32, 64, 128, 256, 512]\n",
    "    dropouts = [0.1, 0.2]\n",
    "    models = []\n",
    "    configurations = []\n",
    "    \n",
    "    for num_layers in layers:\n",
    "        for num_neurons in neurons:\n",
    "            for dropout_rate in dropouts:\n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(LSTM(num_neurons, input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=(num_layers > 1)))\n",
    "                model.add(Dropout(dropout_rate))\n",
    "                \n",
    "                for layer_idx in range(1, num_layers):\n",
    "                    model.add(LSTM(num_neurons, return_sequences=(layer_idx < num_layers - 1)))\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "                \n",
    "                model.add(Dense(1))\n",
    "                \n",
    "                model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "                \n",
    "                models.append(model)\n",
    "                configurations.append({\n",
    "                    \"layers\": num_layers,\n",
    "                    \"neurons\": num_neurons,\n",
    "                    \"dropout\": dropout_rate\n",
    "                })\n",
    "    \n",
    "    return models, configurations\n",
    "\n",
    "look_back = 60\n",
    "trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "models, configurations = list_models(look_back, trainX)\n",
    "\n",
    "print(\"Configurations:\")\n",
    "for idx, config in enumerate(configurations, start=1):\n",
    "    print(f\"Model {idx}: Layers={config['layers']}, Neurons={config['neurons']}, Dropout={config['dropout']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83eaee-72ef-4e0c-a403-0bfc47aeaedd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/1\n",
      "Training Model 1: Layers=1, Neurons=512, Dropout=0.1\n",
      "Epoch 1/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 113ms/step - loss: 0.0252\n",
      "Epoch 2/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 112ms/step - loss: 0.0087\n",
      "Epoch 3/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 114ms/step - loss: 0.0080\n",
      "Epoch 4/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 111ms/step - loss: 0.0080\n",
      "Epoch 5/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 113ms/step - loss: 0.0066\n",
      "Epoch 6/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 113ms/step - loss: 0.0072\n",
      "Epoch 7/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0056\n",
      "Epoch 8/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 102ms/step - loss: 0.0057\n",
      "Epoch 9/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 106ms/step - loss: 0.0053\n",
      "Epoch 10/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 102ms/step - loss: 0.0057\n",
      "Epoch 11/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0057\n",
      "Epoch 12/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 103ms/step - loss: 0.0057\n",
      "Epoch 13/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 103ms/step - loss: 0.0053\n",
      "Epoch 14/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0054\n",
      "Epoch 15/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - loss: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - loss: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - loss: 0.1304\n",
      "Epoch 19/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0944\n",
      "Epoch 20/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.1246\n",
      "Epoch 21/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 104ms/step - loss: 0.0654\n",
      "Epoch 22/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.1934\n",
      "Epoch 23/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0930\n",
      "Epoch 24/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 103ms/step - loss: 0.0797\n",
      "Epoch 25/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 104ms/step - loss: 0.0516\n",
      "Epoch 26/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0771\n",
      "Epoch 27/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 104ms/step - loss: 0.0929\n",
      "Epoch 28/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.1197\n",
      "Epoch 29/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.1618\n",
      "Epoch 30/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0616\n",
      "Epoch 31/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0539\n",
      "Epoch 32/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0064\n",
      "Epoch 33/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0046\n",
      "Epoch 34/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0053\n",
      "Epoch 35/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 104ms/step - loss: 0.0045\n",
      "Epoch 36/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0051\n",
      "Epoch 37/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0051\n",
      "Epoch 38/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0047\n",
      "Epoch 39/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - loss: 0.0041\n",
      "Epoch 40/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0051\n",
      "Epoch 41/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0048\n",
      "Epoch 42/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0043\n",
      "Epoch 43/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 104ms/step - loss: 0.0038\n",
      "Epoch 44/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0051\n",
      "Epoch 45/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - loss: 0.0045\n",
      "Epoch 46/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0038\n",
      "Epoch 47/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - loss: 0.0041\n",
      "Epoch 48/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 105ms/step - loss: 0.0035\n",
      "Epoch 49/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - loss: 0.0474\n",
      "Epoch 50/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - loss: 0.0091\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/b9bk135x3gd6hxg4hr0846t80000gn/T/ipykernel_88062/2498383641.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  new_row[0, -1] = a_predict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 2.37 RMSE\n",
      "Test Score: 14.13 RMSE\n",
      "Training Model 2: Layers=1, Neurons=1024, Dropout=0.1\n",
      "Epoch 1/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 550ms/step - loss: 0.0409\n",
      "Epoch 2/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 549ms/step - loss: 0.0101\n",
      "Epoch 3/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 553ms/step - loss: 0.0093\n",
      "Epoch 4/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 553ms/step - loss: 0.0103\n",
      "Epoch 5/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 551ms/step - loss: 0.0068\n",
      "Epoch 6/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 555ms/step - loss: 0.4570\n",
      "Epoch 7/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 555ms/step - loss: 0.2028\n",
      "Epoch 8/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 555ms/step - loss: 0.1929\n",
      "Epoch 9/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.2720\n",
      "Epoch 10/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.2166\n",
      "Epoch 11/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.1731\n",
      "Epoch 12/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.1027\n",
      "Epoch 13/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.0695\n",
      "Epoch 14/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0732\n",
      "Epoch 15/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 555ms/step - loss: 0.0683\n",
      "Epoch 16/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.0383\n",
      "Epoch 17/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.0581\n",
      "Epoch 18/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.0463\n",
      "Epoch 19/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0566\n",
      "Epoch 20/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.0499\n",
      "Epoch 21/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0434\n",
      "Epoch 22/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0390\n",
      "Epoch 23/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0331\n",
      "Epoch 24/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 556ms/step - loss: 0.0416\n",
      "Epoch 25/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 558ms/step - loss: 0.0335\n",
      "Epoch 26/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0358\n",
      "Epoch 27/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0324\n",
      "Epoch 28/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 558ms/step - loss: 0.0335\n",
      "Epoch 29/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 558ms/step - loss: 0.0269\n",
      "Epoch 30/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 558ms/step - loss: 0.0342\n",
      "Epoch 31/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0280\n",
      "Epoch 32/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 558ms/step - loss: 0.0365\n",
      "Epoch 33/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0311\n",
      "Epoch 34/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0346\n",
      "Epoch 35/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 559ms/step - loss: 0.0418\n",
      "Epoch 36/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 559ms/step - loss: 0.0266\n",
      "Epoch 37/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0297\n",
      "Epoch 38/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 558ms/step - loss: 0.0265\n",
      "Epoch 39/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 558ms/step - loss: 0.0236\n",
      "Epoch 40/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 559ms/step - loss: 0.0314\n",
      "Epoch 41/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 559ms/step - loss: 0.0291\n",
      "Epoch 42/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 558ms/step - loss: 0.0248\n",
      "Epoch 43/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 556ms/step - loss: 0.0264\n",
      "Epoch 44/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 557ms/step - loss: 0.0336\n",
      "Epoch 45/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 559ms/step - loss: 0.0262\n",
      "Epoch 46/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 560ms/step - loss: 0.0272\n",
      "Epoch 47/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 559ms/step - loss: 0.0261\n",
      "Epoch 48/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 562ms/step - loss: 0.0271\n",
      "Epoch 49/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 559ms/step - loss: 0.0328\n",
      "Epoch 50/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 559ms/step - loss: 0.0301\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/b9bk135x3gd6hxg4hr0846t80000gn/T/ipykernel_88062/2498383641.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  new_row[0, -1] = a_predict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 3.48 RMSE\n",
      "Test Score: 33.64 RMSE\n",
      "Training Model 3: Layers=1, Neurons=2048, Dropout=0.1\n",
      "Epoch 1/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1876s\u001b[0m 2s/step - loss: 0.0662\n",
      "Epoch 2/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1882s\u001b[0m 2s/step - loss: 0.1035\n",
      "Epoch 3/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1883s\u001b[0m 2s/step - loss: 0.7963\n",
      "Epoch 4/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1882s\u001b[0m 2s/step - loss: 0.3291\n",
      "Epoch 5/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1882s\u001b[0m 2s/step - loss: 0.4477\n",
      "Epoch 6/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1884s\u001b[0m 2s/step - loss: 0.3272\n",
      "Epoch 7/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1881s\u001b[0m 2s/step - loss: 0.3969\n",
      "Epoch 8/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1901s\u001b[0m 2s/step - loss: 0.2824\n",
      "Epoch 9/50\n",
      "\u001b[1m815/815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1876s\u001b[0m 2s/step - loss: 0.1704\n",
      "Epoch 10/50\n",
      "\u001b[1m166/815\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:34\u001b[0m 3s/step - loss: 0.2419"
     ]
    }
   ],
   "source": [
    "#@title Train and Predict (Find the Optimal Model)\n",
    "\n",
    "def optimal_model(models, configurations, data, train, test, look_back=1, nepochs=10, horizon=10, plot_predictions=False):\n",
    "    results = []\n",
    "\n",
    "    for idx, (model, config) in enumerate(zip(models, configurations), start=1):\n",
    "        print(f\"Training Model {idx}: Layers={config['layers']}, Neurons={config['neurons']}, Dropout={config['dropout']}\")\n",
    "        \n",
    "        #reshape\n",
    "        trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "\n",
    "        #fit\n",
    "        model.fit(trainX, trainY, epochs=nepochs, batch_size=1, verbose=1)\n",
    "\n",
    "        #predict, foecast and plot\n",
    "        testScore =  predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model)\n",
    "\n",
    "        #append results\n",
    "        results.append({\n",
    "            \"model_index\": idx,\n",
    "            \"configuration\": config,\n",
    "            \"test_score\": testScore\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_average_results(models, configurations, data, train, test, look_back=1, nepochs=10, horizon=10, runs=10):\n",
    "    all_results = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print(f\"Run {run + 1}/{runs}\")\n",
    "        results = optimal_model(models, configurations, data, train, test, look_back, nepochs, horizon)\n",
    "        all_results.extend(results)\n",
    "\n",
    "    #aggregate results by model\n",
    "    average_results = {}\n",
    "    for result in all_results:\n",
    "        model_idx = result[\"model_index\"]\n",
    "        if model_idx not in average_results:\n",
    "            average_results[model_idx] = {\n",
    "                \"configuration\": result[\"configuration\"],\n",
    "                \"test_scores\": []\n",
    "            }\n",
    "        average_results[model_idx][\"test_scores\"].append(result[\"test_score\"])\n",
    "\n",
    "    #calculate average train and test scores\n",
    "    for model_idx, scores in average_results.items():\n",
    "        test_avg = np.mean(scores[\"test_scores\"])\n",
    "        average_results[model_idx][\"test_score_avg\"] = test_avg\n",
    "\n",
    "    return average_results\n",
    "\n",
    "models, configurations= list_models(60, trainX)\n",
    "average_results = calculate_average_results(models, configurations, data, train, test, look_back=60, nepochs=50, horizon=10, runs=5)\n",
    "\n",
    "for model_idx, scores in average_results.items():\n",
    "    print(f\"Model {model_idx}:\")\n",
    "    print(f\"  Configuration: {scores['configuration']}\")\n",
    "    print(f\"  Average Test Score: {scores['test_score_avg']:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b4e84-65ec-4571-9d9e-1fcffeea8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Train and Predict\n",
    "\n",
    "def model(data, train, test, look_back=1, nepochs=10, horizon=10, plot_predictions=False):\n",
    "    #reshape\n",
    "    trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "\n",
    "    #create the network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #model.summary()\n",
    "\n",
    "    #fit\n",
    "    model.fit(trainX, trainY, epochs=nepochs, batch_size=1, verbose=1)\n",
    "\n",
    "    #predict, forecast and plot\n",
    "    testScore = predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model)\n",
    "    \n",
    "    return testScore\n",
    "\n",
    "#model(data, train, test, look_back=60, nepochs=50, horizon=10, plot_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c25bc2-6ed0-458a-a534-0044d6fded3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run the Model Several Times\n",
    "\n",
    "n_runs = 50\n",
    "rmse_results = []\n",
    "for i in range(n_runs):\n",
    "    print(f\"Running iteration {i+1}/{n_runs}...\")\n",
    "    test_rmse = model(data, train, test, look_back=60, nepochs=50, horizon=10, plot_predictions=False)  \n",
    "    rmse_results.append(test_rmse)\n",
    "\n",
    "rmse_results = np.array(rmse_results)\n",
    "print(\"All RMSE results:\", rmse_results)\n",
    "print(f\"Mean RMSE: {np.mean(rmse_results):.2f}\")\n",
    "print(f\"Standard Deviation: {np.std(rmse_results):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595e48b-37dd-4446-9d0e-319d9a3e1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Train and Predict (Model Early Stop)\n",
    "\n",
    "def model_early_stop(data, train, test, look_back=1, nepochs=10, horizon=10, plot_predictions=False):\n",
    "    #reshape\n",
    "    trainX, trainY, testX, testY = reshape(train, test, look_back)\n",
    "\n",
    "    #create the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #model.summary()\n",
    "\n",
    "    #early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    #fit\n",
    "    model.fit(trainX, trainY, epochs=nepochs, batch_size=1, verbose=1, validation_data=(testX, testY), callbacks=[early_stop])\n",
    "\n",
    "    #predict, forecast and plot\n",
    "    testScore =  predict_forecast_plot(data, train, test, trainX, trainY, testX, testY, nepochs, look_back, horizon, plot_predictions, model)\n",
    "    \n",
    "    return testScore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
